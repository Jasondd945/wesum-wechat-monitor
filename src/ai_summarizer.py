"""
AI æ€»ç»“ç”Ÿæˆæ¨¡å—
ä½¿ç”¨é€šä¹‰åƒé—® API ç”Ÿæˆæ–‡ç« æ·±åº¦æ€»ç»“
"""

import dashscope
from dashscope import Generation
from typing import Dict


class AISummarizer:
    """AI æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, api_key: str, model: str = "qwen-turbo", max_tokens: int = 1000):
        """
        åˆå§‹åŒ– AI æ€»ç»“ç”Ÿæˆå™¨

        Args:
            api_key: é€šä¹‰åƒé—® API Key
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§ token æ•°ï¼ˆé»˜è®¤ 1000ï¼Œé€‚åˆ 500 å­—æ€»ç»“ï¼‰
        """
        dashscope.api_key = api_key
        self.model = model
        self.max_tokens = max_tokens

    def generate_summary(self, article: Dict, prompt_template: str = None) -> Dict:
        """
        ç”Ÿæˆå•ç¯‡æ–‡ç« æ·±åº¦æ€»ç»“ï¼ˆåŒ…å«åˆ†ç±»æ ‡ç­¾ï¼‰

        Args:
            article: æ–‡ç« ä¿¡æ¯ï¼ˆåŒ…å« title, contentï¼‰
            prompt_template: è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿

        Returns:
            {
                "summary": "æ€»ç»“æ–‡æœ¬",
                "categories": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3"]
            }
        """
        # ä½¿ç”¨é»˜è®¤æç¤ºè¯æˆ–è‡ªå®šä¹‰æç¤ºè¯
        if prompt_template is None:
            prompt_template = """è¯·å°†ä»¥ä¸‹å…¬ä¼—å·æ–‡ç« ç”Ÿæˆæ€»ç»“ï¼Œè¦æ±‚ï¼š

**åˆ†ç±»æ ‡ç­¾**ï¼š
1. é¦–å…ˆè¾“å‡º 3-5 ä¸ªåˆ†ç±»æ ‡ç­¾ï¼ˆå…³é”®è¯ï¼‰
2. ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡è¯æ±‡ï¼ˆ2-4ä¸ªå­—ï¼‰
3. æ ‡ç­¾ä¹‹é—´ç”¨é¡¿å·åˆ†éš”
4. æ ‡ç­¾åº”è¯¥åæ˜ æ–‡ç« çš„æ ¸å¿ƒä¸»é¢˜

**æ–‡ç« æ€»ç»“**ï¼š
5. ç»“æ„åŒ–è¾“å‡ºï¼šä½¿ç”¨ Emoji å›¾æ ‡ä½œä¸ºæ®µè½æ ‡è®°ï¼ˆå¦‚ğŸ¯ã€ğŸ”„ã€ğŸ¤–ç­‰ï¼‰
6. åˆ†æ®µæ¸…æ™°ï¼šæ¯ä¸ªå¤§æ®µæœ‰æ˜ç¡®çš„ä¸»é¢˜æ ‡é¢˜
7. æ·±åº¦è§£æï¼šä¸æ˜¯ç®€å•æ‘˜è¦ç‚¹ï¼Œè€Œæ˜¯ä¿ç•™å…³é”®ä¿¡æ¯å’Œæ•°æ®çš„æ·±åº¦è§£æ
8. æ ¼å¼è§„èŒƒï¼š
   - ä½¿ç”¨åˆ†çº§æ ‡é¢˜ï¼ˆä¸€ã€äºŒã€ä¸‰ï¼‰
   - å…³é”®æ•°æ®ç”¨åŠ ç²—æ ‡è®°
   - åŒ…å«å…·ä½“æ¡ˆä¾‹å’Œç»†èŠ‚
9. å†…å®¹é•¿åº¦ï¼šæ§åˆ¶åœ¨500å­—ä»¥å†…
10. è¡¥å……ç»†èŠ‚ï¼šæœ€åè¡¥å……å…³é”®ç»†èŠ‚å’ŒèƒŒæ™¯ä¿¡æ¯

**è¾“å‡ºæ ¼å¼**ï¼š
ã€æ ‡ç­¾ã€‘æ ‡ç­¾1ã€æ ‡ç­¾2ã€æ ‡ç­¾3

ã€æ€»ç»“ã€‘
ï¼ˆæ–‡ç« æ€»ç»“å†…å®¹...ï¼‰

---

æ–‡ç« æ ‡é¢˜ï¼š{title}

æ–‡ç« å†…å®¹ï¼š
{content}

è¯·æŒ‰æ ¼å¼ç”Ÿæˆï¼š"""

        # æ„å»ºæç¤ºè¯
        prompt = prompt_template.format(
            title=article['title'],
            content=article.get('content', '')[:4000]  # æ‰©å¤§å†…å®¹é•¿åº¦é™åˆ¶
        )

        try:
            # è°ƒç”¨ API
            response = Generation.call(
                model=self.model,
                prompt=prompt,
                max_tokens=self.max_tokens
            )

            if response.status_code == 200:
                ai_text = response.output.text
                # è§£æ AI è¿”å›çš„å†…å®¹ï¼Œæå–æ ‡ç­¾å’Œæ‘˜è¦
                return self._parse_ai_response(ai_text)
            else:
                return {
                    "summary": f"API é”™è¯¯: {response.code} - {response.message}",
                    "categories": []
                }

        except Exception as e:
            return {
                "summary": f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}",
                "categories": []
            }

    def _parse_ai_response(self, ai_text: str) -> Dict:
        """
        è§£æ AI è¿”å›çš„å†…å®¹ï¼Œæå–æ ‡ç­¾å’Œæ‘˜è¦

        Args:
            ai_text: AI è¿”å›çš„å®Œæ•´æ–‡æœ¬

        Returns:
            {
                "summary": "æ‘˜è¦å†…å®¹",
                "categories": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
            }
        """
        import re

        # å°è¯•æå–ã€æ ‡ç­¾ã€‘éƒ¨åˆ†
        categories = []
        summary = ai_text

        # æŸ¥æ‰¾ã€æ ‡ç­¾ã€‘æ ‡è®°ï¼ˆæ”¹è¿›ï¼šåŒ¹é…åˆ°è¡Œå°¾æˆ–ã€æ€»ç»“ã€‘æ ‡è®°ï¼‰
        tag_match = re.search(r'ã€æ ‡ç­¾ã€‘(.+?)(?=ã€æ€»ç»“ã€‘|\n\n|$)', ai_text)
        if tag_match:
            tag_text = tag_match.group(1).strip()
            # è§£ææ ‡ç­¾ï¼ˆæ”¯æŒé¡¿å·ã€é€—å·åˆ†éš”ï¼‰
            categories = re.split(r'[ã€,ï¼Œ\s]+', tag_text)
            categories = list(set([c for c in categories if c.strip()]))
            categories = categories[:5]  # é™åˆ¶ä¸º 5 ä¸ª
            print(f"[DEBUG] Parsed tags from AI: {categories}")

        # æŸ¥æ‰¾ã€æ€»ç»“ã€‘æ ‡è®°
        summary_match = re.search(r'ã€æ€»ç»“ã€‘\s*\n(.+)', ai_text, re.DOTALL)
        if summary_match:
            summary = summary_match.group(1).strip()
        else:
            # å¦‚æœæ²¡æœ‰ã€æ€»ç»“ã€‘æ ‡è®°ï¼Œå»é™¤ã€æ ‡ç­¾ã€‘éƒ¨åˆ†
            summary = re.sub(r'ã€æ ‡ç­¾ã€‘.+', '', ai_text).strip()

        print(f"[DEBUG] AI response parsing - tags: {categories}, summary length: {len(summary)}")

        return {
            "summary": summary,
            "categories": categories
        }

    def generate_simple_summary(self, article: Dict, noise_type: str) -> str:
        """
        ç”Ÿæˆå¹²æ‰°æ–‡ç« çš„ç®€åŒ–æ‘˜è¦ï¼ˆ3-5ä¸ªå…³é”®è¦ç‚¹ï¼Œ100å­—ä»¥å†…ï¼‰

        Args:
            article: æ–‡ç« ä¿¡æ¯
            noise_type: å¹²æ‰°ç±»å‹ï¼ˆæ‹›è˜ã€å¸¦è´§ã€èèµ„ç­‰ï¼‰

        Returns:
            ç®€åŒ–æ‘˜è¦æ–‡æœ¬
        """
        # æ ¹æ®å¹²æ‰°ç±»å‹å®šåˆ¶è¦ç‚¹è¦æ±‚
        points_requirements = {
            "æ‹›è˜": "- æ‹›è˜å…¬å¸\n- æ‹›è˜å²—ä½\n- è–ªèµ„èŒƒå›´\n- å·¥ä½œåœ°ç‚¹\n- å²—ä½è¦æ±‚",
            "å¸¦è´§": "- äº§å“åç§°\n- äº§å“ä»·æ ¼\n- ä¼˜æƒ ä¿¡æ¯\n- è´­ä¹°æ–¹å¼\n- æ´»åŠ¨æ—¶é—´",
            "å¹¿å‘Š": "- å“ç‰Œ/äº§å“\n- æ ¸å¿ƒä¿¡æ¯\n- æ¨å¹¿å†…å®¹",
            "è¯¾ç¨‹": "- è¯¾ç¨‹åç§°\n- è®²å¸ˆ/æœºæ„\n- è¯¾ç¨‹ä»·æ ¼\n- è¯¾ç¨‹æ—¶é•¿\n- æŠ¥åæ–¹å¼",
            "ç¤¾ç¾¤": "- ç¤¾ç¾¤åç§°\n- ç¤¾ç¾¤ç±»å‹\n- åŠ å…¥æ–¹å¼\n- è´¹ç”¨ä¿¡æ¯",
            "æ´»åŠ¨æ¨å¹¿": "- æ´»åŠ¨åç§°\n- æ´»åŠ¨æ—¶é—´\n- æ´»åŠ¨åœ°ç‚¹\n- ç¥¨ä»·ä¿¡æ¯\n- æŠ¥åæ–¹å¼",
            "èèµ„": "- èèµ„å…¬å¸\n- èèµ„è½®æ¬¡\n- èèµ„é‡‘é¢\n- æŠ•èµ„æ–¹\n- å…¬å¸ä¼°å€¼",
            "å…¬å…³": "- å…¬å¸/å“ç‰Œ\n- æ ¸å¿ƒä¿¡æ¯\n- å‘å¸ƒæ—¶é—´\n- ç›¸å…³æ•°æ®"
        }

        requirements = points_requirements.get(noise_type, "- è¦ç‚¹1\n- è¦ç‚¹2\n- è¦ç‚¹3")

        prompt_template = f"""è¯·å°†ä»¥ä¸‹å…¬ä¼—å·æ–‡ç« æå–ä¸ºå…³é”®è¦ç‚¹ï¼Œè¦æ±‚ï¼š

1. æç‚¼3-5ä¸ªå…³é”®è¦ç‚¹
2. æ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡15å­—
3. ä¸¥æ ¼æ§åˆ¶åœ¨100å­—ä»¥å†…
4. å¿…é¡»åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
{requirements}

æ–‡ç« æ ‡é¢˜ï¼š{{title}}

æ–‡ç« å†…å®¹ï¼š
{{content}}

è¯·ç”Ÿæˆå…³é”®è¦ç‚¹ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰ï¼š"""

        # ä½¿ç”¨è¾ƒå°‘çš„ token
        prompt = prompt_template.format(
            title=article['title'],
            content=article.get('content', '')[:2000]
        )

        try:
            response = Generation.call(
                model=self.model,
                prompt=prompt,
                max_tokens=300  # ç®€åŒ–æ‘˜è¦ç”¨æ›´å°‘çš„ token
            )

            if response.status_code == 200:
                return response.output.text
            else:
                return f"API é”™è¯¯: {response.code}"

        except Exception as e:
            return f"ç”Ÿæˆç®€åŒ–æ‘˜è¦å¤±è´¥: {str(e)}"

    def generate_batch_summaries(self, articles: list[Dict]) -> list[Dict]:
        """
        æ‰¹é‡ç”Ÿæˆæ–‡ç« æ·±åº¦æ€»ç»“

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            å¸¦æ€»ç»“çš„æ–‡ç« åˆ—è¡¨
        """
        results = []
        for i, article in enumerate(articles, 1):
            print(f"Generating summary {i}/{len(articles)}: {article['title'][:30]}...")

            summary = self.generate_summary(article)
            article['summary'] = summary
            results.append(article)

        return results


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    summarizer = AISummarizer(api_key="your-api-key-here")

    test_article = {
        'title': 'è€é»„All inç‰©ç†AIï¼æœ€æ–°GPUæ€§èƒ½5å€æå‡',
        'content': 'è‹±ä¼Ÿè¾¾ CEO é»„ä»å‹‹åœ¨ CES 2025 ä¸Šå‘è¡¨ä¸»é¢˜æ¼”è®²ï¼Œå®£å¸ƒæ¨å‡ºæ–°ä¸€ä»£ GPU äº§å“ Blackwellã€‚æ®ä»‹ç»ï¼ŒBlackwell GPU ç›¸æ¯”ä¸Šä¸€ä»£æ€§èƒ½æå‡ 5 å€ï¼Œèƒ½æ•ˆæ¯”æå‡ 2 å€ã€‚'
    }

    summary = summarizer.generate_summary(test_article)
    print("Summary:")
    print(summary)
